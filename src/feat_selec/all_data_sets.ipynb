{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\Desktop\\Memory_genes\\src\n"
     ]
    }
   ],
   "source": [
    "%cd \"../\"\n",
    "%pwd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io \n",
    "import pandas as pd  \n",
    "import pyreadr\n",
    "\n",
    "from load_data import *\n",
    "from pred_score import *\n",
    "from Filter_FS import *\n",
    "from hybrid_FS import *\n",
    "from overlap_genes import *\n",
    "from crossValidation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing seed to get reproducible results\n",
    "random.seed(3)\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with preselected genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7615, 9353)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load preprocess data\n",
    "all_norm = np.array(pd.read_csv('../data/processed_data/all.csv')).T\n",
    "y = np.squeeze(np.array(pd.read_csv('../data/processed_data/y_all.csv')))\n",
    "ind_dataset = np.squeeze(np.array(pd.read_csv('../data/processed_data/size_datasets.csv')))\n",
    "\n",
    "all_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and evaluate\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "pred = model.fit_predict(all_norm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred).to_csv('../data/test', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(606.0, 4554.0, 12996853, 3752)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.squeeze(np.array(pd.read_csv('../data/test')))\n",
    "print(len(pred))\n",
    "\n",
    "computeTP(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7615, 9353) 7615\n",
      "0.11744186046511627\n"
     ]
    }
   ],
   "source": [
    "print(all_norm.shape, len(pred))\n",
    "acc = model.score_\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR =  (606.0, 4554.0, 0.13306982872200263, 0.1390546122074346, 0.9996497302176602, 0.11744186046511627, 0.9997113980464756, 0.8825581395348837, 0.8609453877925654)\n"
     ]
    }
   ],
   "source": [
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information maximizer (MIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c8164de0f63c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFamiliesClusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Scoring'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'N'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_testing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFamiliesClusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mMIM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmean_score_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_score_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Memory_genes\\src\\crossValidation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, Model_test, Scoring_test, maximize_test, kfold, func, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m#Run feature selection on training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m#Evaluate subset on test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Memory_genes\\src\\Filter_FS.py\u001b[0m in \u001b[0;36mMIM\u001b[1;34m(y, x, Model, Scoring, maximize, N, n_neighbors, plot)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m#Compute mutual information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mmutual_information\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mindex_sorted\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutual_information\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \"\"\"\n\u001b[0;32m    447\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0m\u001b[0;32m    449\u001b[0m                         copy, random_state)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1e-10\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[0;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1e-10\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[0;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[1;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cd\u001b[1;34m(c, d, n_neighbors)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mradius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnextafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mk_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mn_queries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             \u001b[0msample_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m             \u001b[0msample_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msample_range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,all_norm, FamiliesClusters, compute_precision,True, 5,  MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluates on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPqyZ49FMaxj"
   },
   "source": [
    "# Anova F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for ANOVA method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,all_norm, FamiliesClusters, compute_precision,True, 5,  ANOVA, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluate on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Every data set but switch which is used for training and which is used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestAll(y:np.array, x:np.array, ind_dataset:list, i:int):\n",
    "    \"\"\"Split the merged data, one data set is keept for testing, the others for training.\n",
    "  \n",
    "      parameters:\n",
    "      y : np.array,\n",
    "        family of each data points\n",
    "      x : np.array,\n",
    "        features of each data points\n",
    "      ind_dataset : list,\n",
    "        list of indices where each data set is stored\n",
    "      i: int, \n",
    "        ind of the data set to keep for testing\n",
    "        \n",
    "\n",
    "      returns:\n",
    "      x_train : np.array,\n",
    "        norm data without the test dataset for training\n",
    "      y_train : np.array,\n",
    "        families of each data point without the test dataset for training\n",
    "      x_test : np.array,\n",
    "        norm data of the test dataset\n",
    "      y_test : np.array,\n",
    "        families of each data point of the test dataset\"\"\"\n",
    "    \n",
    "    ind_i = None\n",
    "    if i == 0:\n",
    "        ind_i = np.arange(0,ind_dataset[i],1)\n",
    "    else:\n",
    "        ind_i = np.arange(ind_dataset[i-1], ind_dataset[i], 1)\n",
    "    \n",
    "    \n",
    "    x_train = np.delete(x, ind_i, axis=0)\n",
    "    y_train = np.delete(y, ind_i)\n",
    "    x_test = x[ind_i,:]\n",
    "    y_test = y[ind_i]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def optimization_on_allsets(y:np.array, x:np.array, ind_dataset:list, Model_test: Callable, Scoring_test: Callable, maximize_test:bool, func: Callable, **kwargs: dict):\n",
    "    \"\"\" \n",
    "  \n",
    "      parameters:\n",
    "      y : np.array,\n",
    "        family of each data points\n",
    "      x : np.array,\n",
    "        features of each data points\n",
    "      ind_dataset : list,\n",
    "        list of indices where each data set is stored\n",
    "      Model_test : Callable,\n",
    "        the model is fitted using this method\n",
    "      Scoring_test: Callable,\n",
    "        scoring function use to evaluate the model\n",
    "      maximize_test: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "      func: Callable,\n",
    "        feature selection function, should return seleted subset and associated score\n",
    "      kwargs: **kwargs : dict,\n",
    "        dictionnary of parameters and their values (kwargs = {'param_name' : value}) to pass to the given method (func)\n",
    "        \n",
    "\n",
    "      returns:\n",
    "      final_subset : np.array,\n",
    "        subset of features with the best score\n",
    "      best_test_score : float,\n",
    "        test score obtained with the best subset of features \"\"\"\n",
    "    \n",
    "    #Store score training and best subset\n",
    "    score_training = []\n",
    "    score_testing = []\n",
    "    final_subset = []\n",
    "    \n",
    "    for i in range(0,len(ind_dataset)):\n",
    "        #Get split data\n",
    "        x_train, y_train, x_test, y_test = getTrainTestAll(y, x, ind_dataset, i)\n",
    "        print(y.shape, y_train.shape, y_test.shape)\n",
    "        print(x.shape, x_train.shape, x_test.shape)\n",
    "        \n",
    "        #Run feature selection on training set\n",
    "        subset, score = func(y_train, x_train, **kwargs)\n",
    "        \n",
    "        #Evaluate subset on test set\n",
    "        model_test = Model_test(np.unique(y_test),Scoring_test,True)\n",
    "        pred_test = model_test.fit_predict(x_test[:, subset],y_test)\n",
    "        test_score = model_test.score(x_test[:, subset],y_test)\n",
    "        \n",
    "        #Store best score and best subset on current folds\n",
    "        score_training.append(score)\n",
    "        score_testing.append(test_score)\n",
    "        final_subset.append(subset)\n",
    "        \n",
    "    return final_subset, score_training, score_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information maximizer (MIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7615,) (7282,) (333,)\n",
      "(7615, 9353) (7282, 9353) (333, 9353)\n"
     ]
    }
   ],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,1500,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = optimization_on_allsets(y,all_norm, ind_dataset, FamiliesClusters, compute_precision,True, MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "wq\n",
    "#Predict and evaluates on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPqyZ49FMaxj"
   },
   "source": [
    "# Anova F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for ANOVA method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = optimization_on_allsets(y,all_norm, ind_dataset, FamiliesClusters, compute_precision,True, ANOVA, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluates on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
