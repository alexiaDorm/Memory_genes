{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dormann/Documents/GitHub/src\n"
     ]
    }
   ],
   "source": [
    "%cd \"../\"\n",
    "%pwd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io \n",
    "import pandas as pd  \n",
    "import pyreadr\n",
    "\n",
    "from load_data import *\n",
    "from pred_score import *\n",
    "from Filter_FS import *\n",
    "from hybrid_FS import *\n",
    "from overlap_genes import *\n",
    "from crossValidation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing seed to get reproducible results\n",
    "random.seed(3)\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with preselected genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7615, 9353)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load preprocess data\n",
    "all_norm = np.array(pd.read_csv('../data/processed_data/all.csv')).T\n",
    "y = np.squeeze(np.array(pd.read_csv('../data/processed_data/y_all.csv')))\n",
    "ind_dataset = np.squeeze(np.array(pd.read_csv('../data/processed_data/size_datasets.csv')))\n",
    "\n",
    "all_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and evaluate\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "pred = model.fit_predict(all_norm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_norm.shape, len(pred))\n",
    "acc = model.score_\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information maximizer (MIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,all_norm, FamiliesClusters, compute_precision,True, 5,  MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluates on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))\n",
    "print(model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create .csv with names of this subset\n",
    "get_best_genes_names(subset, '../data/processed_data/allgenes_interest.csv', '../data/optimized_subsets/allgenes_bestMIM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPqyZ49FMaxj"
   },
   "source": [
    "# Anova F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for ANOVA method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,all_norm, FamiliesClusters, compute_precision,True, 5,  ANOVA, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluate on whole data  set\n",
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "x_subset = all_norm[:, subset]\n",
    "pred = model.fit_predict(x_subset,y)\n",
    "\n",
    "print(\"TP, FP, ratio, sensitivity, specificity, precision, NPV, FDR, FNR = \", compute_statTP(y,pred))    \n",
    "print(model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create .csv with names of this subset\n",
    "get_best_genes_names(subset, '../data/processed_data/allgenes_interest.csv', '../data/optimized_subsets/allgenes_bestANOVA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Every data set but switch which is used for training and which is used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestAll(y:np.array, x:np.array, ind_dataset:list, i:int):\n",
    "    \"\"\"Split the merged data, one data set is keept for testing, the others for training.\n",
    "  \n",
    "      parameters:\n",
    "      y : np.array,\n",
    "        family of each data points\n",
    "      x : np.array,\n",
    "        features of each data points\n",
    "      ind_dataset : list,\n",
    "        list of indices where each data set is stored\n",
    "      i: int, \n",
    "        ind of the data set to keep for testing\n",
    "        \n",
    "\n",
    "      returns:\n",
    "      x_train : np.array,\n",
    "        norm data without the test dataset for training\n",
    "      y_train : np.array,\n",
    "        families of each data point without the test dataset for training\n",
    "      x_test : np.array,\n",
    "        norm data of the test dataset\n",
    "      y_test : np.array,\n",
    "        families of each data point of the test dataset\"\"\"\n",
    "    \n",
    "    ind_i = None\n",
    "    if i == 0:\n",
    "        ind_i = np.arange(0,ind_dataset[i],1)\n",
    "    else:\n",
    "        ind_i = np.arange(ind_dataset[i-1], ind_dataset[i], 1)\n",
    "    \n",
    "    \n",
    "    x_train = np.delete(x, ind_i, axis=0)\n",
    "    y_train = np.delete(y, ind_i)\n",
    "    x_test = x[ind_i,:]\n",
    "    y_test = y[ind_i]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def optimization_on_allsets(y:np.array, x:np.array, ind_dataset:list, Model_test: Callable, Scoring_test: Callable, maximize_test:bool, func: Callable, **kwargs: dict):\n",
    "    \"\"\" \n",
    "  \n",
    "      parameters:\n",
    "      y : np.array,\n",
    "        family of each data points\n",
    "      x : np.array,\n",
    "        features of each data points\n",
    "      ind_dataset : list,\n",
    "        list of indices where each data set is stored\n",
    "      Model_test : Callable,\n",
    "        the model is fitted using this method\n",
    "      Scoring_test: Callable,\n",
    "        scoring function use to evaluate the model\n",
    "      maximize_test: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "      func: Callable,\n",
    "        feature selection function, should return seleted subset and associated score\n",
    "      kwargs: **kwargs : dict,\n",
    "        dictionnary of parameters and their values (kwargs = {'param_name' : value}) to pass to the given method (func)\n",
    "        \n",
    "\n",
    "      returns:\n",
    "      final_subset : np.array,\n",
    "        subset of features with the best score\n",
    "      best_test_score : float,\n",
    "        test score obtained with the best subset of features \"\"\"\n",
    "    \n",
    "    #Store score training and best subset\n",
    "    score_training = []\n",
    "    score_testing = []\n",
    "    final_subset = []\n",
    "    \n",
    "    for i in range(0,len(ind_dataset)):\n",
    "        #Get split data\n",
    "        x_train, y_train, x_test, y_test = getTrainTestAll(y, x, ind_dataset, i)\n",
    "        print(y.shape, y_train.shape, y_test.shape)\n",
    "        print(x.shape, x_train.shape, x_test.shape)\n",
    "        \n",
    "        #Run feature selection on training set\n",
    "        subset, score = func(y_train, x_train, **kwargs)\n",
    "        \n",
    "        #Evaluate subset on test set\n",
    "        model_test = Model_test(np.unique(y_test),Scoring_test,True)\n",
    "        pred_test = model_test.fit_predict(x_test[:, subset],y_test)\n",
    "        test_score = model_test.score(x_test[:, subset],y_test)\n",
    "        \n",
    "        #Store best score and best subset on current folds\n",
    "        score_training.append(score)\n",
    "        score_testing.append(test_score)\n",
    "        final_subset.append(subset)\n",
    "        \n",
    "    return final_subset, score_training, score_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information maximizer (MIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,1500,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset_MIM, score_training, score_testing = optimization_on_allsets(y,all_norm, ind_dataset, FamiliesClusters, compute_precision,True, MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create .csv with names of this subset\n",
    "for i, subset in enumerate(subset_MIM):\n",
    "    get_best_genes_names(subset, '../data/processed_data/allgenes_interest.csv', '../data/optimized_subsets/allgenes_bestMIM' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPqyZ49FMaxj"
   },
   "source": [
    "# Anova F test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for ANOVA method\n",
    "N = np.arange(80,2000,50)\n",
    "kwargs = {'Model': FamiliesClusters, 'Scoring': compute_precision,'maximize': True,'N': N, 'plot': True} \n",
    "\n",
    "subset_ANOVA, score_training, score_testing = optimization_on_allsets(y,all_norm, ind_dataset, FamiliesClusters, compute_precision,True, ANOVA, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create .csv with names of this subset\n",
    "for i, subset in enumerate(subset_ANOVA):\n",
    "    get_best_genes_names(subset, '../data/processed_data/allgenes_interest.csv', '../data/optimized_subsets/allgenes_bestANOVA' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
