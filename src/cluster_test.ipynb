{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math \n",
    "from typing import AnyStr, Callable, Tuple\n",
    "from sklearn.base import ClusterMixin,BaseEstimator\n",
    "from scipy.cluster.hierarchy import ward, cut_tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from load_data import *\n",
    "from pred_score import *\n",
    "from Filter_FS import *\n",
    "from hybrid_FS import *\n",
    "from overlap_genes import *\n",
    "from crossValidation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a4b6",
   "metadata": {},
   "source": [
    "# Iterative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e40d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeClustering(ClusterMixin, BaseEstimator):\n",
    "    '''\n",
    "    Iterative Families clustering\n",
    "    Hierachical clustering with the ward2 criterion, use the pearson's correlation as the distance measure.\n",
    "    Parameters\n",
    "    ----------\n",
    "    family_interest: np.array,\n",
    "        list of family of interest\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_clusters_ : int\n",
    "        The number of clusters found by the algorithm.\n",
    "    labels_ : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point.\n",
    "    family_interest: np.array,\n",
    "        list of family of interest.\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model.\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, family_interest_:np.array, Scoring_:Callable, maximize_:bool):\n",
    "        super().__init__()\n",
    "        self.family_interest_ = family_interest_\n",
    "        self.Scoring_ = Scoring_\n",
    "        self.maximize_ = maximize_\n",
    "        \n",
    "    def fit(self, X:np.array, y:np.array, N:int =2, iterations:int =20, subset: np.array = None):\n",
    "        '''Fit data using hierachical clustering with the ward2 criterion and use the spearman correlation as the distance measure and predict.\n",
    "        \n",
    "        parameters:\n",
    "        -------\n",
    "        x : np.array,\n",
    "            features of each data points\n",
    "        y : np.array,\n",
    "            family of each data points\n",
    "        N : int,\n",
    "            max number of\n",
    "        iterations : int,\n",
    "            number of iterative clustering\n",
    "    \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self,\n",
    "            return fitted self'''\n",
    "        \n",
    "        #Iterative clustering algorithm\n",
    "        result = iterative_clustering(X,y , N, iterations)\n",
    "        r = result[0]\n",
    "        rcsv = pd.DataFrame(r)\n",
    "        rcsv.to_csv('../data/test.csv', index=False)\n",
    "        \n",
    "        \n",
    "        #Score the cluster and determine the number of clusters\n",
    "        TP,FP,tot = test_prediction_multiple_overlap_3(result, result, result,y)\n",
    "        score = TP/(TP+FP)\n",
    "        self.score_ = score\n",
    "        \n",
    "        return self, TP, FP  \n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d80c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,20,1,20,20,1,100,100,100]\n",
    "B = [100,30,100,30,30,100,1,1,1]\n",
    "norm_data = np.array([A,B])\n",
    "y_test = [1,2,1,2,2,1,3,3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20944d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IterativeClustering(np.unique(y_test),compute_precision,True)\n",
    "result  = model.fit(norm_data,y_test,N=2, iterations=20)\n",
    "model.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de5cf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load preprocess data\n",
    "AE3= np.array(pd.read_csv ('../data/processed_data/AE3.csv'))\n",
    "y = np.array(AE3[:,-1],dtype=int)\n",
    "AE3 = AE3[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad061bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 448\n"
     ]
    }
   ],
   "source": [
    "model = IterativeClustering(np.unique(y),compute_precision,True)\n",
    "result,TP,FP  = model.fit(AE3,y,N=2, iterations=20)\n",
    "model.score_\n",
    "\n",
    "print(TP,FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb8a69e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gz/s90yhf3d4yg_q6r76fs2lg380000gq/T/ipykernel_43152/1007554052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterativeClustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Scoring'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterativeClustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mMIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmean_score_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_score_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/crossValidation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, Model_test, Scoring_test, maximize_test, kfold, func, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m#Run feature selection on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#Evaluate subset on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/Filter_FS.py\u001b[0m in \u001b[0;36mMIM\u001b[0;34m(y, x, Model, Scoring, maximize, N, n_neighbors, plot)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#Evaluate the error on given subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mScoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaximize\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m#Convert best_subset into features indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/pred_score.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y, x, Model, Scoring, maximize)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;31m#Fit the model on the given data, evaluate the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mScoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,1500,30)\n",
    "kwargs = {'Model': IterativeClustering, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,AE3, IterativeClustering, compute_precision,True, 5,  MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluate on whole data  set\n",
    "model = IterativeClustering(np.unique(y),compute_precision,True)\n",
    "result  = model.fit(AE3,y,N=2, iterations=20)\n",
    "model.score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a401b6e",
   "metadata": {},
   "source": [
    "# Repeated prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed16b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblingHierarchical(ClusterMixin, BaseEstimator):\n",
    "    '''\n",
    "    Hierachical clustering with the ward2 criterion, use the spearmann's correlation as the distance measure, on N subsets of genes. \n",
    "    Then, use ensembling method to give final cluster assignments.\n",
    "    Parameters\n",
    "    ----------\n",
    "    family_interest: np.array,\n",
    "        list of family of interest\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "    subsets: list,\n",
    "        list of the different subsets of genes\n",
    "    ensembling_: str,\n",
    "        ensembling method to produce final clustering\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_clusters_ : int\n",
    "        The number of clusters found by the algorithm.\n",
    "    labels_ : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point.\n",
    "    family_interest: np.array,\n",
    "        list of family of interest.\n",
    "    Scoring_ : Callable,\n",
    "        scoring function use to evaluate the model.\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize.\n",
    "    subsets_: list,\n",
    "        list of the different subsets of genes\n",
    "    ensembling_: str,\n",
    "        ensembling method to produce final clustering\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, family_interest_:np.array, Scoring_:Callable, maximize_:bool, subsets: list, ensembling: str):\n",
    "        super().__init__()\n",
    "        self.family_interest_ = family_interest_\n",
    "        self.Scoring_ = Scoring_\n",
    "        self.maximize_ = maximize_\n",
    "        self.subsets_ = subsets\n",
    "        self.ensembling_ = ensembling\n",
    "        \n",
    "    def fit(self, X:np.array, y:np.array, NmaxCluster:int=None):\n",
    "        '''Fit data using hierachical clustering with the ward2 criterion and use the spearman correlation as the distance measure and predict \n",
    "        on provided subsets.\n",
    "        \n",
    "        parameters:\n",
    "        -------\n",
    "        x : np.array,\n",
    "            features of each data points\n",
    "        y : np.array,\n",
    "            family of each data points\n",
    "        NmaxCluster : int,\n",
    "            max number of cells in a cluster\n",
    "\n",
    "        return\n",
    "        -------\n",
    "        self,\n",
    "            return fitted self'''\n",
    "        \n",
    "        clustering = []\n",
    "        #Cluster data using the different subsets of features\n",
    "        for subset in self.subsets_:\n",
    "            model = FamiliesClusters(self.family_interest_, self.Scoring_, self.maximize_)\n",
    "            pred = model.fit_predict(X,y)\n",
    "            clustering.append(pred)\n",
    "            \n",
    "        #Get the final clustering from the individual clustering result\n",
    "        if self.ensembling_ == 'voting':\n",
    "            final_ensembling = ensembling_voting(clustering)\n",
    "        elif self.esembling_ == 'all':\n",
    "            final_ensembling = ensembling_all(clustering)\n",
    "        \n",
    "        #Score the cluster and determine the number of clusters\n",
    "        score = self.Scoring_(y,final_ensembling)\n",
    "        N = len(np.unique(final_ensembling))\n",
    "   \n",
    "        self.n_clusters_, self.labels_, self.score_ = N, final_ensembling, score\n",
    "        return self\n",
    "    \n",
    "    def fit_predict(self, X:np.array, y:np.array,NmaxCluster:int = None):\n",
    "        self.fit(X,y,NmaxCluster)\n",
    "        \n",
    "        return self.labels_ \n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe2a475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembling_voting(clustering:list):\n",
    "    \"\"\" Compute the final clustering from given individual clustering. \n",
    "    Two cells that are the most of the clusterings predict together are together in the final clustering. \n",
    "  \n",
    "      parameters:\n",
    "      clustering: list,\n",
    "        list of the independent clusterings from which the final clustering is computed\n",
    "\n",
    "      return:\n",
    "      final_label: np.array,\n",
    "        final computed \n",
    "    \"\"\"\n",
    "    #Compute co_occurrence matrix of the clustering\n",
    "    co_occurrence = np.zeros((len(clustering[0]), len(clustering[0])))\n",
    "    for cluster in clustering:\n",
    "        co_occurrence += outer_equal(cluster)\n",
    "    \n",
    "    #Compute final clustering with majority voting\n",
    "    N_vote = math.floor(len(clustering)/2 + 1) #Vote necessary to consider two cells same family\n",
    "    same_family = co_occurrence >= N_vote \n",
    "    for i in range(0,len(clustering[0])):\n",
    "        for j in range(0,i+1):\n",
    "            same_family[i,j] = False\n",
    "    #Get indexes of cell together\n",
    "    ind_together = np.nonzero(same_family)\n",
    "    final_label = np.zeros((len(clustering[0],)))\n",
    "    \n",
    "    for i in range(0,len(ind_together[0])):\n",
    "        first_cell, second_cell = ind_together[0][i], ind_together[1][i]\n",
    "        if final_label[first_cell] == 0 or  final_label[second_cell] == 0:\n",
    "            if final_label[first_cell] == 0 and  final_label[second_cell] == 0:\n",
    "                final_label[first_cell], final_label[second_cell] = np.max(final_label) + 1, np.max(final_label) + 1\n",
    "            else:\n",
    "                final_label[first_cell], final_label[second_cell] = np.max([final_label[first_cell], final_label[second_cell]]), np.max([final_label[first_cell], final_label[second_cell]])\n",
    "        else:\n",
    "            final_label[final_label == final_label[second_cell]] = final_label[first_cell]\n",
    "    \n",
    "    return final_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed6e929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembling_all(clustering:list):\n",
    "    \"\"\" Compute the final clustering from given individual clustering. \n",
    "    Two cells need to be predicted together in all the clusters, otherwise the cell family is undertermined. \n",
    "  \n",
    "      parameters:\n",
    "      clustering: list,\n",
    "        list of the independent clusterings from which the final clustering is computed\n",
    "\n",
    "      return:\n",
    "      final_label: np.array,\n",
    "        final computed \n",
    "    \"\"\"\n",
    "    ##Compute co_occurrence matrix of the clustering\n",
    "    co_occurrence = np.zeros((len(clustering[0]), len(clustering[0])))\n",
    "    for cluster in clustering:\n",
    "        co_occurrence += outer_equal(cluster)\n",
    "    \n",
    "    #Compute final clustering \n",
    "    N_vote =  len(clustering)\n",
    "    same_family = co_occurrence >= N_vote \n",
    "    for i in range(0,len(clustering[0])):\n",
    "        for j in range(0,i+1):\n",
    "            same_family[i,j] = False\n",
    "    #Get indexes of cell together\n",
    "    ind_together = np.nonzero(same_family)\n",
    "    final_label = np.zeros((len(clustering[0],)))\n",
    "    \n",
    "    for i in range(0,len(ind_together[0])):\n",
    "        first_cell, second_cell = ind_together[0][i], ind_together[1][i]\n",
    "        if final_label[first_cell] == 0 or  final_label[second_cell] == 0:\n",
    "            if final_label[first_cell] == 0 and  final_label[second_cell] == 0:\n",
    "                final_label[first_cell], final_label[second_cell] = np.max(final_label) + 1, np.max(final_label) + 1\n",
    "            else:\n",
    "                final_label[first_cell], final_label[second_cell] = np.max([final_label[first_cell], final_label[second_cell]]), np.max([final_label[first_cell], final_label[second_cell]])\n",
    "        else:\n",
    "            final_label[final_label == final_label[second_cell]] = final_label[first_cell]\n",
    "    \n",
    "    return final_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80741090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recovery(final_label:np.array):\n",
    "    return len(np.nonzero(final_label)[0])/len(final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6365abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering=[[1,1,2,2,1,2,3,3,3],[1,1,2,2,2,2,3,3,3],[1,1,2,2,1,2,3,3,1]]\n",
    "final = ensembling_all(clustering)\n",
    "compute_recovery(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e20d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling_genes(subset:np.array, N:int, p_mutate:float):\n",
    "    subsets = []\n",
    "    \n",
    "    for i in range(0,N):\n",
    "        subsets.append(mutate(subset,p_mutate))\n",
    "        \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f97b17b-9acf-4811-b5b8-3d3e827b990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 280)\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "#Load preprocess data\n",
    "AE3= np.array(pd.read_csv ('../data/processed_data/AE3.csv'))\n",
    "y = np.array(AE3[:,-1],dtype=int)\n",
    "AE3 = AE3[:,0:-1]\n",
    "\n",
    "genes_AE3 = np.squeeze(pd.read_csv ('../data/processed_data/AE3genes_interest.csv'))\n",
    "gene_optimized = np.squeeze(pd.read_csv ('../data/optimized_subsets/AE3genes_bestANOVA.csv'))\n",
    "\n",
    "ind_opt_genes = []\n",
    "for gene in gene_optimized:\n",
    "    ind_opt_genes = np.append(ind_opt_genes, int(np.squeeze(np.where(genes_AE3 == gene))))\n",
    "ind_opt_genes= list(ind_opt_genes.astype(int))\n",
    "\n",
    "#Only keep the optimized genes\n",
    "AE3 = AE3[:,ind_opt_genes]\n",
    "print(AE3.shape)\n",
    "\n",
    "subset = np.ones((len(gene_optimized),))\n",
    "subsets = subsampling_genes(subset, 1, 0.25)\n",
    "print(len(subsets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80c1f7e8-25be-4526-80c4-830ff943daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01585014409221902"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='voting')\n",
    "result  = model.fit_predict(X = AE3, y= y)\n",
    "model.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3434079-8a04-4de4-9cde-ad317d110f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039301310043668124"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "pred = model.fit_predict(AE3,y)\n",
    "model.score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
