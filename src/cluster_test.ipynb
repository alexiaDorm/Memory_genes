{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math \n",
    "from typing import AnyStr, Callable, Tuple\n",
    "from sklearn.base import ClusterMixin,BaseEstimator\n",
    "from scipy.cluster.hierarchy import ward, cut_tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.decomposition import PCA\n",
    "import ClusterEnsembles as CE\n",
    "\n",
    "from load_data import *\n",
    "from pred_score import *\n",
    "from Filter_FS import *\n",
    "from hybrid_FS import *\n",
    "from overlap_genes import *\n",
    "from crossValidation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeClustering(ClusterMixin, BaseEstimator):\n",
    "    '''\n",
    "    Iterative Families clustering\n",
    "    Hierachical clustering with the ward2 criterion, use the pearson's correlation as the distance measure.\n",
    "    Parameters\n",
    "    ----------\n",
    "    family_interest: np.array,\n",
    "        list of family of interest\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_clusters_ : int\n",
    "        The number of clusters found by the algorithm.\n",
    "    labels_ : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point.\n",
    "    family_interest: np.array,\n",
    "        list of family of interest.\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model.\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, family_interest_:np.array, Scoring_:Callable, maximize_:bool):\n",
    "        super().__init__()\n",
    "        self.family_interest_ = family_interest_\n",
    "        self.Scoring_ = Scoring_\n",
    "        self.maximize_ = maximize_\n",
    "        \n",
    "    def fit(self, X:np.array, y:np.array, N:int =2, iterations:int =20, subset: np.array = None):\n",
    "        '''Fit data using hierachical clustering with the ward2 criterion and use the spearman correlation as the distance measure and predict.\n",
    "        \n",
    "        parameters:\n",
    "        -------\n",
    "        x : np.array,\n",
    "            features of each data points\n",
    "        y : np.array,\n",
    "            family of each data points\n",
    "        N : int,\n",
    "            max number of\n",
    "        iterations : int,\n",
    "            number of iterative clustering\n",
    "    \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self,\n",
    "            return fitted self'''\n",
    "        \n",
    "        #Iterative clustering algorithm\n",
    "        result = iterative_clustering(X,y , N, iterations)\n",
    "        r = result[0]\n",
    "        rcsv = pd.DataFrame(r)\n",
    "        rcsv.to_csv('../data/test.csv', index=False)\n",
    "        \n",
    "        \n",
    "        #Score the cluster and determine the number of clusters\n",
    "        TP,FP,tot = test_prediction_multiple_overlap_3(result, result, result,y)\n",
    "        score = TP/(TP+FP)\n",
    "        self.score_ = score\n",
    "        \n",
    "        return self, TP, FP  \n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,20,1,20,20,1,100,100,100]\n",
    "B = [100,30,100,30,30,100,1,1,1]\n",
    "norm_data = np.array([A,B])\n",
    "y_test = [1,2,1,2,2,1,3,3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IterativeClustering(np.unique(y_test),compute_precision,True)\n",
    "result  = model.fit(norm_data,y_test,N=2, iterations=20)\n",
    "model.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load preprocess data\n",
    "AE3= np.array(pd.read_csv ('../data/processed_data/AE3.csv'))\n",
    "y = np.array(AE3[:,-1],dtype=int)\n",
    "AE3 = AE3[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017167381974248927\n",
      "8 458\n"
     ]
    }
   ],
   "source": [
    "model = IterativeClustering(np.unique(y),compute_precision,True)\n",
    "result,TP,FP  = model.fit(AE3,y,N=2, iterations=20)\n",
    "print(model.score_)\n",
    "\n",
    "print(TP,FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gz/s90yhf3d4yg_q6r76fs2lg380000gq/T/ipykernel_43152/1007554052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterativeClustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Scoring'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterativeClustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mMIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmean_score_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_score_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/crossValidation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, Model_test, Scoring_test, maximize_test, kfold, func, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m#Run feature selection on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#Evaluate subset on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/Filter_FS.py\u001b[0m in \u001b[0;36mMIM\u001b[0;34m(y, x, Model, Scoring, maximize, N, n_neighbors, plot)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#Evaluate the error on given subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mScoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaximize\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m#Convert best_subset into features indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/src/pred_score.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y, x, Model, Scoring, maximize)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;31m#Fit the model on the given data, evaluate the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mScoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "#Define parameters for MIM method\n",
    "N = np.arange(80,1500,30)\n",
    "kwargs = {'Model': IterativeClustering, 'Scoring': compute_precision,'maximize': True,'N': N, 'n_neighbors': 3, 'plot': True} \n",
    "\n",
    "subset, score_training, score_testing = cross_validation(y,AE3, IterativeClustering, compute_precision,True, 5,  MIM, **kwargs)\n",
    "\n",
    "mean_score_test, std_score_test = np.mean(score_testing), np.std(score_testing)    \n",
    "print('test', mean_score_test, std_score_test)\n",
    "\n",
    "#Predict and evaluate on whole data  set\n",
    "model = IterativeClustering(np.unique(y),compute_precision,True)\n",
    "result  = model.fit(AE3,y,N=2, iterations=20)\n",
    "model.score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1540)\n",
      "1540\n"
     ]
    }
   ],
   "source": [
    "#Load preprocess data\n",
    "AE3= np.array(pd.read_csv ('../data/processed_data/AE3.csv'))\n",
    "y = np.array(AE3[:,-1],dtype=int)\n",
    "AE3 = AE3[:,0:-1]\n",
    "\n",
    "genes_AE3 = np.squeeze(pd.read_csv ('../data/processed_data/AE3genes_interest.csv'))\n",
    "gene_optimized = np.squeeze(pd.read_csv ('../data/optimized_subsets/AE3genes_bestANOVA.csv'))\n",
    "\n",
    "ind_opt_genes = []\n",
    "for gene in gene_optimized:\n",
    "    ind_opt_genes = np.append(ind_opt_genes, int(np.squeeze(np.where(genes_AE3 == gene))))\n",
    "ind_opt_genes= list(ind_opt_genes.astype(int))\n",
    "\n",
    "#Only keep the optimized genes\n",
    "AE3 = AE3[:,ind_opt_genes]\n",
    "print(AE3.shape)\n",
    "\n",
    "subset = np.ones((len(gene_optimized),))\n",
    "subsets = subsampling_genes(subset, 101, 0.25)\n",
    "print(len(subsets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619047619047619 0.6756756756756757\n"
     ]
    }
   ],
   "source": [
    "model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='voting', threshold_voting = 0.5)\n",
    "result  = model.fit_predict(X = AE3, y= y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333 0.2972972972972973\n"
     ]
    }
   ],
   "source": [
    "model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='voting', threshold_voting = 1)\n",
    "result  = model.fit_predict(X = AE3, y= y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thereshold:  0.1 0.1327319587628866 0.9129129129129129\n",
      "thereshold:  0.2 0.3282442748091603 0.8528528528528528\n",
      "thereshold:  0.30000000000000004 0.42118863049095606 0.8228228228228228\n",
      "thereshold:  0.4 0.6481481481481481 0.7567567567567568\n",
      "thereshold:  0.5 0.7619047619047619 0.6756756756756757\n",
      "thereshold:  0.6 0.8344370860927153 0.6186186186186187\n",
      "thereshold:  0.7000000000000001 0.8518518518518519 0.5675675675675675\n",
      "thereshold:  0.8 0.8869565217391304 0.5015015015015015\n",
      "thereshold:  0.9 0.8775510204081632 0.45345345345345345\n",
      "thereshold:  1.0 0.9833333333333333 0.2972972972972973\n"
     ]
    }
   ],
   "source": [
    "thereshold = np.linspace(0.1,1.0,10)\n",
    "\n",
    "for t in thereshold:    \n",
    "    model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='voting', threshold_voting = t)\n",
    "    result  = model.fit_predict(X = AE3, y= y)\n",
    "    print('thereshold: ', t, model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6826923076923077 0.7807807807807807\n"
     ]
    }
   ],
   "source": [
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "pred = model.fit_predict(AE3,y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 333)\n",
      "0.4294478527607362 0.990990990990991\n"
     ]
    }
   ],
   "source": [
    "model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='cspa')\n",
    "result  = model.fit_predict(X = AE3, y = y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnsemblingHierarchical(np.unique(y),compute_precision,True,subsets = subsets, ensembling='hgpa')\n",
    "result  = model.fit_predict(X = AE3, y = y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using other genesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load AE3 data\n",
    "AE3 = pd.read_csv ('../data/merged_data/D0.csv')\n",
    "AE3 = AE3.set_index('Unnamed: 0')\n",
    "y_AE3 = np.squeeze(np.array(pd.read_csv('../data/merged_data/y_AE4.csv')))\n",
    "\n",
    "AE3_master = pyreadr.read_r('../data/data_master/Master_Almut_AE4_20_3t5_nocellcyclesplit.rds')\n",
    "AE3_master = AE3_master[None]\n",
    "AE3_master = AE3_master.set_index('gene')     \n",
    "\n",
    "CV2_of_mean = AE3_master['P_value_estimate_CV2_ofmeans_20_']\n",
    "intraCV2 = AE3_master['P_value_estimate_intraCV2_20_']\n",
    "corr = AE3_master['P_value_estimate_intraCV2_20_']\n",
    "\n",
    "CV2_of_mean = CV2_of_mean[CV2_of_mean <= 0.05].index\n",
    "pd.DataFrame(CV2_of_mean).to_csv('../data/optimized_subsets/AE4CV2mean.csv', index=False)\n",
    "intraCV2 = intraCV2[intraCV2 <= 0.05].index\n",
    "pd.DataFrame(intraCV2).to_csv('../data/optimized_subsets/AE4intraCV2.csv', index=False)\n",
    "corr  = corr[corr  <= 0.05].index\n",
    "pd.DataFrame(corr).to_csv('../data/optimized_subsets/AE4corr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_CV2 = get_ind_genes(AE3.index, CV2_of_mean)\n",
    "ind_CV2_genes = np.zeros((len(AE3.index),))\n",
    "ind_CV2_genes[ind_CV2] = True\n",
    "ind_CV2_genes = list(ind_CV2_genes.astype(bool))\n",
    "\n",
    "ind_intraCV2 = get_ind_genes(AE3.index, intraCV2)\n",
    "ind_intraCV2_genes = np.zeros((len(AE3.index),))\n",
    "ind_intraCV2_genes[ind_intraCV2] = True\n",
    "ind_intraCV2_genes = list(ind_intraCV2_genes.astype(bool))\n",
    "\n",
    "ind_corr = get_ind_genes(AE3.index, corr)\n",
    "ind_corr_genes = np.zeros((len(AE3.index),))\n",
    "ind_corr_genes[ind_corr] = True\n",
    "ind_corr_genes= list(ind_corr_genes.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_genes(all_genes:np.array, subset:np.array):\n",
    "    ind = []\n",
    "    for gene in subset:\n",
    "        ind = np.append(ind, int(np.squeeze(np.where(all_genes == gene))))\n",
    "        ind = list(ind.astype(int))\n",
    "        \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 333)\n",
      "0.5174129353233831 0.7477477477477478\n"
     ]
    }
   ],
   "source": [
    "subsets = [np.squeeze([ind_CV2_genes]), np.squeeze([ind_intraCV2_genes]), np.squeeze([ind_corr_genes])]\n",
    "model = EnsemblingHierarchical(np.unique(y_AE3),compute_precision,True,subsets = subsets, ensembling='voting', threshold_voting = 0.5)\n",
    "result  = model.fit_predict(X = np.array(AE3).T, y= y_AE3)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised genes subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "import numpy as np\n",
    "\n",
    "def compute_cophe_coeff(orign_dists:np.array, Z:np.array):\n",
    "    '''Compute the Cophenetic coefficient from the original distance matrix and generated dendrogram of clustering\n",
    "        parameters:\n",
    "        -------\n",
    "        orign_dists : np.array,\n",
    "            original distance matrix before clustering\n",
    "        Z : np.array,\n",
    "            dendrogram of the clustering to evaluate\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        corr_coeff:float [0,1],\n",
    "            computed Cophenetic coefficient '''\n",
    "    cophe_dists = cophenet(Z) \n",
    "    corr_coef = np.corrcoef(orign_dists, cophe_dists)[0,1]\n",
    "    \n",
    "    return corr_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math \n",
    "from typing import AnyStr, Callable, Tuple\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import ClusterMixin,BaseEstimator\n",
    "from scipy.cluster.hierarchy import ward, cut_tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy_cut_tree_balanced import cut_tree_balanced\n",
    "\n",
    "from pred_score import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamiliesClusters(ClusterMixin, BaseEstimator):\n",
    "    '''\n",
    "    Families clustering\n",
    "    Hierachical clustering with the ward2 criterion, use the spearman correlation as the distance measure.\n",
    "    Parameters\n",
    "    ----------\n",
    "    family_interest: np.array,\n",
    "        list of family of interest\n",
    "    Scoring : Callable,\n",
    "        scoring function use to evaluate the model\n",
    "    maximize: bool,\n",
    "        if True the scoring function is maximize, else it is minimize\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_clusters_ : int\n",
    "        The number of clusters found by the algorithm.\n",
    "    labels_ : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point.\n",
    "    family_interest: np.array,\n",
    "        list of family of interest.\n",
    "    Scoring_ : Callable,\n",
    "        scoring function use to evaluate the model.\n",
    "    maximize_: bool,\n",
    "        if True the scoring function is maximize, else it is minimize.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, family_interest_:np.array, Scoring_:Callable, maximize_:bool):\n",
    "        super().__init__()\n",
    "        self.family_interest_ = family_interest_\n",
    "        self.Scoring_ = Scoring_\n",
    "        self.maximize_ = maximize_\n",
    "        \n",
    "    def fit(self, X:np.array, y:np.array, NmaxCluster:int = None):\n",
    "        '''Fit data using hierachical clustering with the ward2 criterion and use the spearman correlation as the distance measure and predict.\n",
    "        \n",
    "        parameters:\n",
    "        -------\n",
    "        x : np.array,\n",
    "            features of each data points\n",
    "        y : np.array,\n",
    "            family of each data points\n",
    "        NmaxCluster : int,\n",
    "            max number of cells in a cluster\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self,\n",
    "            return fitted self'''\n",
    "        \n",
    "        #Compute the spearman correlation of X\n",
    "        X_pd = pd.DataFrame(X.T)\n",
    "        corr_expr= X_pd.corr(method= 'spearman')\n",
    "        corr_expr = np.array((1 - corr_expr)/2)\n",
    "        corr_expr = upper_tri_indexing(corr_expr)**2 #Squared for ward2 criterion\n",
    "        \n",
    "        if(np.shape(X.T)[0] == 1):\n",
    "            corr_expr.fill(1)\n",
    "        \n",
    "        #Create clustering tree using hierarchical clustering with spearmann correlation and ward2 criterion\n",
    "        Z = ward(corr_expr)\n",
    "        \n",
    "        #Cut the tree into clusters of maximum size equal to the number of cells in the largest family in data set\n",
    "        if NmaxCluster == None:\n",
    "            Nmax = round(np.mean(np.unique(y,return_counts=True)[1]))\n",
    "        else:\n",
    "            Nmax = NmaxCluster\n",
    "        \n",
    "        clustering = np.squeeze(cut_tree_balanced(Z, max_cluster_size = Nmax)[0])\n",
    "        \n",
    "        #Assign all cells predicted alone in a cluster the label 0\n",
    "        clustering += 1\n",
    "        values, counts = np.unique(clustering, return_counts=True)\n",
    "        onecell_family = values[np.where(counts==1)]\n",
    "        for fam in onecell_family:\n",
    "            clustering[clustering == fam] = 0\n",
    "        \n",
    "        #Compute recovery\n",
    "        self.recovery = compute_recovery(clustering)\n",
    "    \n",
    "        #Score the cluster and determine the number of clusters\n",
    "        if self.Scoring_ != compute_cophe_coeff:\n",
    "            score = self.Scoring_(y,clustering)\n",
    "        else:\n",
    "            score = self.Scoring_(corr_expr,Z)\n",
    "            \n",
    "        N = len(np.unique(clustering))\n",
    "   \n",
    "        self.n_clusters_, self.labels_, self.score_ = N, clustering, score\n",
    "        return self\n",
    "    \n",
    "    def fit_predict(self, X:np.array, y:np.array,NmaxCluster:int = None):\n",
    "        self.fit(X,y,NmaxCluster)\n",
    "        \n",
    "        return self.labels_      \n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        #Error come from here y_true and X not same size as self.labels_ -> function fit_as\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 11894)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE3= np.array(pd.read_csv ('../data/processed_data/AE3.csv'))\n",
    "y = np.array(AE3[:,-1],dtype=int)\n",
    "AE3 = AE3[:,0:-1]\n",
    "AE3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22874411254286686 0.6726726726726727\n"
     ]
    }
   ],
   "source": [
    "model = FamiliesClusters(np.unique(y),compute_cophe_coeff,True)\n",
    "pred = model.fit_predict(AE3,y)\n",
    "print(model.score_, model.recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/optimized_subsets/AE3genes_bestMIM.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4140a5d2904a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgenes_AE3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'../data/processed_data/AE3genes_interest.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgene_optimized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'../data/optimized_subsets/AE3genes_bestMIM.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mind_opt_genes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgene\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgene_optimized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/optimized_subsets/AE3genes_bestMIM.csv'"
     ]
    }
   ],
   "source": [
    "genes_AE3 = np.squeeze(pd.read_csv ('../data/processed_data/AE3genes_interest.csv'))\n",
    "gene_optimized = np.squeeze(pd.read_csv ('../data/optimized_subsets/AE3genes_bestMIM.csv'))\n",
    "\n",
    "ind_opt_genes = []\n",
    "for gene in gene_optimized:\n",
    "    ind_opt_genes = np.append(ind_opt_genes, int(np.squeeze(np.where(genes_AE3 == gene))))\n",
    "ind_opt_genes= list(ind_opt_genes.astype(int))\n",
    "\n",
    "#Only keep the optimized genes\n",
    "AE3 = AE3[:,ind_opt_genes]\n",
    "print(AE3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FamiliesClusters(np.unique(y),compute_precision,True)\n",
    "pred = model.fit_predict(AE3,y)\n",
    "print(model.score_, model.recovery)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
